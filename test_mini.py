"""
ä½¿ç”¨ OpenRouterMiniClient è¿›è¡Œæµ‹è¯•
ä½¿ç”¨ gpt-4.1-mini æ¨¡å‹ï¼Œæˆæœ¬æ›´ä½
"""

import json
import argparse
from datetime import datetime
from pathlib import Path

from core.llm.openrouter_client import OpenRouterClient
from planner.decompose_agent import DecomposeAgent
from core.schemas.PredictionTask import PredictionTask
from core.utils.smart_matcher import SmartMatcher

def save_plan_to_log(plan, task_id: str, log_dir: str = "log"):
    """
    å°† DecompositionPlan ä¿å­˜åˆ° log ç›®å½•ï¼Œæ ¼å¼åŒ–ä¸ºå¯è¯»çš„ JSON
    
    Args:
        plan: DecompositionPlan å¯¹è±¡
        task_id: ä»»åŠ¡ ID
        log_dir: æ—¥å¿—ç›®å½•è·¯å¾„
    """
    # åˆ›å»º log ç›®å½•
    Path(log_dir).mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{task_id}_{timestamp}_plan.json"
    filepath = Path(log_dir) / filename
    
    # å°† DecompositionPlan è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
    plan_dict = {
        "task": {
            "task_id": plan.task.task_id,
            "task_type": plan.task.task_type,
            "target_entity": plan.task.target_entity,
            "target_metric": plan.task.target_metric,
            "event_description": plan.task.event_description,
            "resolved_time": plan.task.resolved_time,
            "answer_instructions": plan.task.answer_instructions,
        },
        "global_assumptions": plan.global_assumptions,
        "placeholders": plan.placeholders,
        "factors": []
    }
    
    # è½¬æ¢æ¯ä¸ª factor
    for factor in plan.factors:
        factor_dict = {
            "factor_name": factor.factor_name,
            "decision_logic": factor.decision_logic,
            "output_fields": factor.output_fields,
            "variables": factor.variables,
            "notes": factor.notes,
            "tasks": []
        }
        
        # è½¬æ¢æ¯ä¸ª task
        for task in factor.tasks:
            task_dict = {
                "id": task.id,
                "kind": task.kind,
                "goal": task.goal,
                "tool": task.tool,
                "params": task.params,
                "compute": task.compute,
                "writes": task.writes,
            }
            factor_dict["tasks"].append(task_dict)
        
        plan_dict["factors"].append(factor_dict)
    
    # ä¿å­˜ä¸ºæ ¼å¼åŒ–çš„ JSON
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(plan_dict, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… è®¡åˆ’å·²ä¿å­˜åˆ°: {filepath}")
    return filepath


# ä½¿ç”¨ mini å®¢æˆ·ç«¯è¿›è¡Œæµ‹è¯•ï¼ˆæ”¯æŒ --task-id ä»æ•°æ®é›†ä¸­åŠ è½½ä»»åŠ¡ï¼‰
llm = OpenRouterClient(
    model="openai/gpt-4.1-mini",  # ä½¿ç”¨ mini ç‰ˆæœ¬é™ä½æˆæœ¬
    max_tokens=16000,
    temperature=0  # æµ‹è¯•æ—¶ä½¿ç”¨ 0 æ¸©åº¦ä»¥è·å¾—ç¡®å®šæ€§ç»“æœ
)

# è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆæ”¯æŒ --task-id ä¸ --data-path å¯é€‰ï¼‰
parser = argparse.ArgumentParser()
parser.add_argument("--task-id", dest="task_id", type=str, default=None, help="Task ID to load from JSONL")
parser.add_argument("--data-path", dest="data_path", type=str, default=None, help="Path to JSONL data file")
args, _ = parser.parse_known_args()

# ä½¿ç”¨ TaskLoader æŒ‰ ID åŠ è½½ä»»åŠ¡ï¼›è‹¥æœªæä¾›åˆ™å›é€€åˆ°å†…ç½®ç¤ºä¾‹
task = None
if args.task_id:
    from core.utils.task_loader import TaskLoader
    if args.data_path:
        loader = TaskLoader(data_path=args.data_path)
    else:
        try:
            loader = TaskLoader()
        except FileNotFoundError:
            # fallback åˆ°ä»“åº“å†…ç½®æ•°æ®æ–‡ä»¶ data/standardized_data.jsonl
            project_root = Path(__file__).parent
            fallback_path = project_root / "data" / "standardized_data.jsonl"
            loader = TaskLoader(data_path=str(fallback_path))
    task = loader.load_task_by_id(args.task_id)

if task is None:
    # é»˜è®¤ç¤ºä¾‹ä»»åŠ¡ï¼Œä¾¿äºç›´æ¥è¿è¡Œè„šæœ¬
    task = PredictionTask(
        task_id="demo_task",
        task_question="""You are an agent that can predict future events. The event to be predicted: "What will be the low of NVDA stock (NVDA) for the day on 2025-10-30?"

IMPORTANT: Your final answer MUST end with \\boxed{YOUR_PREDICTION} format, where YOUR_PREDICTION is a numerical value representing the predicted stock price.""",
        metadata={
            "end_time": "2025-10-30",
            "dataset_name": "demo",
        },
    )

matcher = SmartMatcher()
knowhow, match_result = matcher.match(task)

agent = DecomposeAgent(llm)

# åŒ¹é…ç»“æœ
print("=" * 80)
print("KnowHow åŒ¹é…ç»“æœ:")
print("=" * 80)
print(f"  ID: {match_result.metadata.id}")
print(f"  æ¥æº: {match_result.matched_by}")
print(f"  ç½®ä¿¡åº¦: {match_result.confidence:.2f}")
if match_result.reasoning:
    print(f"  çº¿ç´¢: {match_result.reasoning}")
print()

# å…ˆçœ‹ prompt
print("=" * 80)
print("PROMPT é¢„è§ˆ:")
print("=" * 80)
print(agent.preview_prompt(task, knowhow))
print("=" * 80)
print()

# çœŸæ­£ç”Ÿæˆ Planï¼ˆè¿”å› dataclassï¼Œå¯ç›´æ¥å–‚ SubAgent Runnerï¼‰
print("æ­£åœ¨ç”Ÿæˆè®¡åˆ’...")
plan = agent.plan(task, knowhow)

print("=" * 80)
print("âœ… è®¡åˆ’ç”ŸæˆæˆåŠŸ!")
print("=" * 80)

# ä¿å­˜è®¡åˆ’åˆ° log ç›®å½•
log_file = save_plan_to_log(plan, task.task_id)
print()

# æ‰“å°è®¡åˆ’æ‘˜è¦
print("=" * 80)
print("è®¡åˆ’æ‘˜è¦:")
print("=" * 80)
print(f"ä»»åŠ¡ ID: {plan.task.task_id}")
print(f"ä»»åŠ¡ç±»å‹: {plan.task.task_type}")
print(f"ç›®æ ‡å®ä½“: {plan.task.target_entity}")
print(f"å› å­æ•°é‡: {len(plan.factors)}")
print()

for i, factor in enumerate(plan.factors, 1):
    print(f"  {i}. {factor.factor_name}")
    print(f"     - ä»»åŠ¡æ•°: {len(factor.tasks)}")
    print(f"     - è¾“å‡ºå­—æ®µ: {', '.join(factor.output_fields)}")
print()

# æ‰“å°ä½¿ç”¨ç»Ÿè®¡
print("=" * 80)
print("Token ä½¿ç”¨ç»Ÿè®¡:")
print("=" * 80)
stats = llm.get_usage_stats()
for key, value in stats.items():
    print(f"  {key}: {value}")
print()

print(f"ğŸ“ è¯¦ç»†è®¡åˆ’å·²ä¿å­˜è‡³: {log_file}")
