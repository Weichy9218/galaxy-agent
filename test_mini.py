"""
ä½¿ç”¨ OpenRouterMiniClient è¿›è¡Œæµ‹è¯•
ä½¿ç”¨ gpt-4.1-mini æ¨¡å‹ï¼Œæˆæœ¬æ›´ä½
"""

import json
import os
from datetime import datetime
from pathlib import Path

from core.llm.openrouter_mini_client import OpenRouterMiniClient
from knowhow_store.finance.stock_price import StockPriceKnowHow
from planner.decompose_agent import DecomposeAgent
from core.schemas.PredictionTask import PredictionTask

def save_plan_to_log(plan, task_id: str, log_dir: str = "log"):
    """
    å°† DecompositionPlan ä¿å­˜åˆ° log ç›®å½•ï¼Œæ ¼å¼åŒ–ä¸ºå¯è¯»çš„ JSON
    
    Args:
        plan: DecompositionPlan å¯¹è±¡
        task_id: ä»»åŠ¡ ID
        log_dir: æ—¥å¿—ç›®å½•è·¯å¾„
    """
    # åˆ›å»º log ç›®å½•
    Path(log_dir).mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{task_id}_{timestamp}_plan.json"
    filepath = Path(log_dir) / filename
    
    # å°† DecompositionPlan è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
    plan_dict = {
        "task": {
            "task_id": plan.task.task_id,
            "task_type": plan.task.task_type,
            "target_entity": plan.task.target_entity,
            "target_metric": plan.task.target_metric,
            "event_description": plan.task.event_description,
            "resolved_time": plan.task.resolved_time,
            "answer_instructions": plan.task.answer_instructions,
        },
        "global_assumptions": plan.global_assumptions,
        "placeholders": plan.placeholders,
        "factors": []
    }
    
    # è½¬æ¢æ¯ä¸ª factor
    for factor in plan.factors:
        factor_dict = {
            "factor_name": factor.factor_name,
            "decision_logic": factor.decision_logic,
            "output_fields": factor.output_fields,
            "variables": factor.variables,
            "notes": factor.notes,
            "tasks": []
        }
        
        # è½¬æ¢æ¯ä¸ª task
        for task in factor.tasks:
            task_dict = {
                "id": task.id,
                "kind": task.kind,
                "goal": task.goal,
                "tool": task.tool,
                "params": task.params,
                "compute": task.compute,
                "writes": task.writes,
            }
            factor_dict["tasks"].append(task_dict)
        
        plan_dict["factors"].append(factor_dict)
    
    # ä¿å­˜ä¸ºæ ¼å¼åŒ–çš„ JSON
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(plan_dict, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… è®¡åˆ’å·²ä¿å­˜åˆ°: {filepath}")
    return filepath


# ä½¿ç”¨ mini å®¢æˆ·ç«¯è¿›è¡Œæµ‹è¯•
llm = OpenRouterMiniClient(
    model="openai/gpt-4.1-mini",  # ä½¿ç”¨ mini ç‰ˆæœ¬é™ä½æˆæœ¬
    max_tokens=16000,
    temperature=0  # æµ‹è¯•æ—¶ä½¿ç”¨ 0 æ¸©åº¦ä»¥è·å¾—ç¡®å®šæ€§ç»“æœ
)

knowhow = StockPriceKnowHow()

# æ„å»ºç¬¦åˆ PredictionTask è¦æ±‚çš„å‚æ•°
task = PredictionTask(
    task_id="t001",
    task_question="""The event to be predicted: "What will be the low of NVDA stock be for the day on 2025-10-30?"
    
IMPORTANT: Your final answer MUST end with \\boxed{YOUR_PREDICTION} format, where YOUR_PREDICTION is a numerical value representing the predicted stock price.""",
    metadata={
        "end_time": "2025-10-30",
        "dataset_name": "test_dataset"
    }
)

agent = DecomposeAgent(llm)

# å…ˆçœ‹ prompt
print("=" * 80)
print("PROMPT é¢„è§ˆ:")
print("=" * 80)
print(agent.preview_prompt(task, knowhow))
print("=" * 80)
print()

# çœŸæ­£ç”Ÿæˆ Planï¼ˆè¿”å› dataclassï¼Œå¯ç›´æ¥å–‚ SubAgent Runnerï¼‰
print("æ­£åœ¨ç”Ÿæˆè®¡åˆ’...")
plan = agent.plan(task, knowhow)

print("=" * 80)
print("âœ… è®¡åˆ’ç”ŸæˆæˆåŠŸ!")
print("=" * 80)

# ä¿å­˜è®¡åˆ’åˆ° log ç›®å½•
log_file = save_plan_to_log(plan, task.task_id)
print()

# æ‰“å°è®¡åˆ’æ‘˜è¦
print("=" * 80)
print("è®¡åˆ’æ‘˜è¦:")
print("=" * 80)
print(f"ä»»åŠ¡ ID: {plan.task.task_id}")
print(f"ä»»åŠ¡ç±»å‹: {plan.task.task_type}")
print(f"ç›®æ ‡å®ä½“: {plan.task.target_entity}")
print(f"å› å­æ•°é‡: {len(plan.factors)}")
print()

for i, factor in enumerate(plan.factors, 1):
    print(f"  {i}. {factor.factor_name}")
    print(f"     - ä»»åŠ¡æ•°: {len(factor.tasks)}")
    print(f"     - è¾“å‡ºå­—æ®µ: {', '.join(factor.output_fields)}")
print()

# æ‰“å°ä½¿ç”¨ç»Ÿè®¡
print("=" * 80)
print("Token ä½¿ç”¨ç»Ÿè®¡:")
print("=" * 80)
stats = llm.get_usage_stats()
for key, value in stats.items():
    print(f"  {key}: {value}")
print()

print(f"ğŸ“ è¯¦ç»†è®¡åˆ’å·²ä¿å­˜è‡³: {log_file}")

